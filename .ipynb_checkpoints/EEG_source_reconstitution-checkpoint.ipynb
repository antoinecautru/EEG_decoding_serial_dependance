{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ac410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_parameters(N, T, device):\n",
    "    \"\"\"\n",
    "    Initializes the parameters of the model\n",
    "    Input:\n",
    "        N: int, Number of sources for the model\n",
    "        T: int, Length of time signals from which we wish to reconstruct the sources\n",
    "        device: instance of class torch.optim.Adam\n",
    "    Output:\n",
    "        Beta: torch.tensor of 1 element, parameter that embodies the delay between a source and a distant point due to speed of signal propagation\n",
    "        Gamma: torch.tensor of size=(N,), scales the decay in 1/r² of source signals as follows: \n",
    "            amplitude ~ 1/(1+Gamma[i]*r²) where r is the distance to the source i. This way, each source can have its own space decay factor\n",
    "        Sources_pos: torch.tensor of size=(N,2). Source_pos[i,:] is the coordinates of the source n°i\n",
    "        Sources: torch.tensor of size=(N,T). Sources[i,:] is the signal of the source n°i\n",
    "    \"\"\"\n",
    "    # initialize Beta to 0\n",
    "    Beta = torch.tensor(0., dtype=torch.float32, requires_grad = True, device=device)\n",
    "    # initialize each Gamma to 20 (arbitrary)\n",
    "    Gamma = 20*torch.ones(size=(N,), dtype=torch.float32, device=device)\n",
    "    Gamma.requires_grad_()\n",
    "    # initialize the sources locations as random values in [0,1]x[0,1]\n",
    "    Sources_pos = torch.rand(size=(N,2), dtype=torch.float32, requires_grad = True, device=device)\n",
    "    # initialize each source to a zero-signal of length T\n",
    "    Sources = torch.zeros(size=(N,T), dtype=torch.float32, requires_grad = True, device=device)\n",
    "    return Beta, Gamma, Sources_pos, Sources\n",
    "\n",
    "\n",
    "def predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Function that takes as input a location in space and the parameters of the model and that returns the estimated signal at this location\n",
    "    Input:\n",
    "        X: torch.tensor of size (2,) \n",
    "        parameters: [Beta, Gamma, Sources_pos, Sources]\n",
    "    Output:\n",
    "        Y: torch.tensor of size=(T,) where T is the length of the source signals. Y is the estimated signal at the X location\n",
    "    \"\"\"\n",
    "    pos = X.reshape(1,2)\n",
    "    Beta, Gamma, Sources_pos, Sources = parameters\n",
    "    N, T = Sources.shape\n",
    "\n",
    "    # initialize output to a zero-signal of length T\n",
    "    Y = torch.zeros(size=(T,))\n",
    "    # compute the pairwise distance (L2 norm) between X and each source\n",
    "    pairwise_dist = torch.cdist(Sources_pos, pos, p=2.0)\n",
    "    if Beta==0:\n",
    "        # in case if we do not want to model the time delay due to the distance to the source.\n",
    "        Sources_delayed = Sources # no delay\n",
    "    else:\n",
    "        Sources_delayed = torch.zeros_like(Sources)\n",
    "        # we want the output to be a weighted sum of the sources considering the time delay due to the distance to each source\n",
    "        for i in range(N):\n",
    "            # we first compute the delayed source signal n°i at the location X without rescaling the signal\n",
    "            # we model it as follows: delayed_source_i(loc=X, time=t) = source_i(time=t-Beta*dist(source_loc_i, X))\n",
    "            dist = pairwise_dist[i]\n",
    "            Sources_delayed[i,int(Beta*dist):] = Sources[i,:T-int(Beta*dist)]\n",
    "        Sources_delayed.requires_grad_()\n",
    "    # Compute the weighted sum of the delayed sources with the factors 1/(1+gamma[i]*dist²(source_loc_i, X))\n",
    "    Y = torch.sum(1/(1+Gamma.reshape(-1,1)*pairwise_dist.reshape(-1,1)**2) * Sources_delayed, dim=0)\n",
    "    Y.requires_grad_()\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def Beta_gradient(Y_true, Y, X, parameters):\n",
    "    \"\"\"\n",
    "    Function that computes the gradient of the loss (defined below) with respect to the parameter Beta. \n",
    "    loss = sum_{t=1:T,i=1:N}(||Y_i(t)-Y_true_i(t)||²)\n",
    "    Because the loss was not differentiable with respect to this parameter (which appears in the indices of the tensors with requires_grad=True), \n",
    "    it was necessary to give an explicit value of the gradient.\n",
    "    Input:\n",
    "        Y_true: torch.tensor of size=(T,). Real signal at the location X (supposed to be an EEG channel)\n",
    "        Y: torch.tensor of size=(T,). Estimated signal at location X with the model and the parameters\n",
    "        X: torch.tensor of size (2,). Location of channel\n",
    "        parameters: [Beta, Gamma, Sources_pos, Sources]\n",
    "    Output:\n",
    "        Y: torch.tensor of size=(T,) where T is the length of the source signals. Y is the estimated signal at the X location\n",
    "    \"\"\"\n",
    "    Beta, Gamma, Sources_pos, Sources = parameters\n",
    "    N, T = Sources.shape\n",
    "    J = Y_true.shape[0]\n",
    "    pairwise_dist = torch.cdist(Sources_pos, X, p=2.0)\n",
    "    mini, maxi = torch.tensor(0), torch.tensor(T)\n",
    "    Sources_delayed = torch.zeros(size=(N,J,T))\n",
    "    for i in range(N):\n",
    "        for j in range(J):\n",
    "            dist = pairwise_dist[i,j]\n",
    "            index = torch.tensor(int(Beta*dist))\n",
    "            Sources_delayed[i,j,torch.clamp(index,mini,maxi):] = Sources[i,:torch.clamp(T-index, mini,maxi)]\n",
    "            \n",
    "    Shifted = torch.roll(Sources_delayed, -1, 2)\n",
    "    grad = 0\n",
    "    for i in range(N):\n",
    "        for j in range(J):\n",
    "            grad += torch.sum(2*(Y_true[j,:]-Y[j,:]) * pairwise_dist[i,j]/(1+Gamma[i]*pairwise_dist[i,j]**2) * (Shifted[i,j,:] - Sources_delayed[i,j,:]))\n",
    "    return 0.1*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_steps, parameters, X, Y_true, lr=1e-3, verbose=True):\n",
    "    \"\"\"\n",
    "    Trains the model by learning the parameters to best reproduce the signals Y_true at the channels locations X\n",
    "    Input:\n",
    "        num_steps: int, steps of learning\n",
    "        parameters: [Beta, Gamma, Sources_pos, Sources]\n",
    "        Y_true: torch.tensor of size=(T,). Real signal at the location X (supposed to be an EEG channel)\n",
    "        X: torch.tensor of size (2,). Location of channel\n",
    "        lr: float, learning rate\n",
    "        verbose: Bool. If True, plot the loss against time at the end of the learning\n",
    "    Output: Stored values of the parameters during the learning. Useful for plots. \n",
    "        torch.tensor(Betas)\n",
    "        torch.tensor(Gammas)\n",
    "        torch.tensor(positions)\n",
    "    \"\"\"\n",
    "    Beta, Gamma, Sources_pos, Sources = parameters\n",
    "    optimizer = torch.optim.Adam(parameters, lr)\n",
    "    losses = []\n",
    "    Betas = []\n",
    "    Gammas = []\n",
    "    positions = []\n",
    "    for step in range(num_steps):\n",
    "        # predict signals at locations X with current parameters\n",
    "        Y = torch.zeros_like(Y_true)\n",
    "        # compute quadratic loss (MSE)\n",
    "        loss = 0\n",
    "        for k in range(len(X)):\n",
    "            Y[k] = predict(X[k], parameters)\n",
    "            loss += torch.sum((Y[k] -Y_true[k])**2)\n",
    "        print(\"loss:\", loss)\n",
    "        # compute the gradient of the loss with respect to parameter Beta (considered at non-differentiable by pytorch because of indexing)\n",
    "        #Beta_update = torch.clamp(Beta - lr*Beta_gradient(Y_true, Y, X, parameters), 0, None)\n",
    "        #Beta.data = torch.tensor(Beta_update)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        Betas.append(Beta.item())\n",
    "        Gammas.append(Gamma.clone().detach().tolist())\n",
    "        positions.append(Sources_pos.clone().detach().tolist())\n",
    "        if verbose and step % 100 == 0:\n",
    "            print(f\"step={step} - loss={loss.item():0.4f}\")\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if verbose:\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "\n",
    "    return torch.tensor(Betas), torch.tensor(Gammas), torch.tensor(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a fake dataset\n",
    "# number of recording channels\n",
    "n_channels = 50\n",
    "channels_pos = torch.rand(n_channels,2)\n",
    "\n",
    "# number of real sources\n",
    "n_sources = 8\n",
    "sources_pos_true = torch.rand(n_sources,2)\n",
    "\n",
    "# time window\n",
    "T = 100\n",
    "\n",
    "# signals at the sources\n",
    "sources_true = torch.zeros((n_sources,T))\n",
    "sources_true[0,:] = 1* torch.cos(torch.linspace(0,20,T))\n",
    "sources_true[1,:] = torch.sin(2*torch.linspace(0,20,T))\n",
    "sources_true[2,:] = 0.5*torch.cos(3*torch.linspace(0,20,T))\n",
    "sources_true[3,:] = torch.sin(torch.exp(torch.linspace(0,20,T)))\n",
    "sources_true[4,:] = 0.1*torch.cos(8*torch.linspace(0,20,T))\n",
    "sources_true[5,:] = torch.sin(2*torch.linspace(0,20,T))\n",
    "sources_true[6,:] = 0.1*torch.cos(2*torch.linspace(0,20,T))\n",
    "sources_true[7,:] = 0.5*torch.cos(torch.exp(torch.linspace(0,20,T)))\n",
    "\n",
    "# choose the parameters for the propagation and space decay of sources\n",
    "Beta = torch.tensor(0.)\n",
    "Gamma = 20*torch.ones(size=(n_sources,))\n",
    "exact_parameters = Beta, Gamma, sources_pos_true, sources_true\n",
    "\n",
    "# compute the signals at the channel locations using these parameters\n",
    "Channels = torch.zeros((n_channels, T))\n",
    "for j in range(n_channels):\n",
    "    with torch.no_grad():\n",
    "        Channels[j,:] = predict(channels_pos[j], exact_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to 'cuda' if you have a GPU available.\n",
    "device = torch.device(\"cpu\")\n",
    "steps = 1000\n",
    "lr = 1e-2\n",
    "\n",
    "# Create dataset and move to device\n",
    "# X : locations of the channels\n",
    "X = channels_pos\n",
    "# Y_true: true signals at these locations\n",
    "Y_true = torch.tensor(Channels, dtype=torch.float32)\n",
    "X = X.to(device)\n",
    "Y_true = Y_true.to(device)\n",
    "\n",
    "# Create model\n",
    "# Number of sources we wish to model\n",
    "N = 10\n",
    "parameters = get_model_parameters(N, T, device)\n",
    "\n",
    "\n",
    "def initialize_sources(parameters, X, Y_true, init_steps=200):\n",
    "    \"\"\"\n",
    "    Creates an intermediate model to make the learning faster.\n",
    "    This function makes a first update of the parameters of the model, using a source reconstruction based on signal power.\n",
    "    Input:\n",
    "        parameters: [Beta, Gamma, Sources_pos, Sources]\n",
    "        X: torch.tensor of size (2,). Location of channel\n",
    "        Y_true: torch.tensor of size=(T,). Real signal at the location X (supposed to be an EEG channel)\n",
    "        init_steps: number of learning steps during the source power reconstruction\n",
    "    Output:\n",
    "        power_parameters: parameters of the model that predicts the power of signal at any location x considering the powers at the channels locations\n",
    "        Betas_power: values of Beta during this first approximation phase\n",
    "        Gammas_power: values of Gamma\n",
    "        positions_power: successive positions of the sources during this first approximation phase\n",
    "    \"\"\"\n",
    "    # compute the received power at each channel location\n",
    "    Y_power_true = torch.sqrt(torch.sum(Y_true**2, dim=1))\n",
    "    # build a model of power sources reconstruction\n",
    "    power_parameters = get_model_parameters(N, 1, device)\n",
    "    # train the model to estimate the source locations as well as Gamma and Beta\n",
    "    Betas_power, Gammas_power, positions_power = train_model(init_steps, power_parameters, X, Y_power_true, lr)\n",
    "    # get the updated model parameters\n",
    "    Beta_power, Gamma_power, Sources_pos_power, Sources_power = power_parameters\n",
    "    # use these values to do the first update of the final model parameters\n",
    "    Beta, Gamma, Sources_pos, Sources = parameters\n",
    "    Gamma.data = Gamma_power.clone().detach()\n",
    "    Sources_pos.data = Sources_pos_power.clone().detach()\n",
    "    return power_parameters, Betas_power, Gammas_power, positions_power\n",
    "\n",
    "# Estimate the sources positions using the power of the signal at the channels.\n",
    "init_steps = 500\n",
    "power_parameters, Betas_power, Gammas_power, positions_power = initialize_sources(parameters, X, Y_true, init_steps)\n",
    "\n",
    "# Train the final model\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "Betas, Gammas, positions = train_model(steps, parameters, X, Y_true, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sources powers estimated with the first approximation model\n",
    "powers_init_pred = power_parameters[3]\n",
    "# get the predicted power\n",
    "#powers_init_pred = torch.sqrt(torch.sum(sources_init_pred**2, dim=1))\n",
    "powers_init_pred = powers_init_pred/torch.max(powers_init_pred)\n",
    "\n",
    "# get the sources signals estimated with the real model\n",
    "sources_pred = parameters[3]\n",
    "powers_pred = torch.sqrt(torch.sum(sources_pred**2, dim=1))\n",
    "powers_pred = powers_pred/torch.max(powers_pred)\n",
    "\n",
    "# get the power of the real sources\n",
    "powers_true = torch.sqrt(torch.sum(sources_true**2, axis=1))\n",
    "powers_true = powers_true/torch.max(powers_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot parameters during source power reconstruction\n",
    "plt.subplot(221)\n",
    "plt.plot(Gammas_power)\n",
    "plt.title(\"Gammas\")\n",
    "plt.subplot(222)\n",
    "plt.title(\"Sources and Channels during source power reconstruction\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.scatter(positions_power[::5,:,0], positions_power[::5,:,1], c='blue', label=\"source successive estimated positions\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    power_pos = power_parameters[2]\n",
    "    plt.scatter(power_pos[:,0],power_pos[:,1],c='black',s = 100*powers_init_pred, label=\"source final estimated position\")\n",
    "    channels_pos = X\n",
    "    plt.scatter(channels_pos[:,0],channels_pos[:,1],c='green', label=\"channels\")\n",
    "    init_pos = exact_parameters[2]\n",
    "    plt.scatter(init_pos[:,0],init_pos[:,1],c='red',s=100*powers_true, alpha =0.5, label = \"real source positions\")\n",
    "plt.legend()\n",
    "\n",
    "# plot parameters evolution after initialization\n",
    "plt.subplot(223)\n",
    "plt.plot(Gammas)\n",
    "plt.title(\"Gammas\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.subplot(224)\n",
    "plt.title(\"Sources and Channels during source reconstruction\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.scatter(positions[::5,:,0], positions[::5,:,1], c='blue', label=\"source successive estimated positions\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos = parameters[2]\n",
    "    plt.scatter(pos[:,0],pos[:,1],c='black',s = 100*powers_pred, label=\"source final estimated position\")\n",
    "    channels_pos = X\n",
    "    plt.scatter(channels_pos[:,0],channels_pos[:,1],c='green', label=\"channels\")\n",
    "    init_pos = exact_parameters[2]\n",
    "    plt.scatter(init_pos[:,0],init_pos[:,1],c='red',s=100*powers_true, alpha =0.5, label = \"real source positions\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "with torch.no_grad():\n",
    "    plt.subplot(221)\n",
    "    plt.plot(predict(torch.tensor(channels_pos[0]), parameters),'b')\n",
    "    plt.plot(Channels[0],'r')\n",
    "    plt.subplot(222)\n",
    "    plt.plot(predict(torch.tensor(channels_pos[1]), parameters),'b')\n",
    "    plt.plot(Channels[1],'r')\n",
    "    plt.subplot(223)\n",
    "    plt.plot(predict(torch.tensor([1.,1.]), parameters),'b')\n",
    "    plt.plot(predict(torch.tensor([1.,1.]), exact_parameters),'r')\n",
    "    plt.subplot(224)\n",
    "    plt.plot(predict(torch.tensor([0.,0.]), parameters),'b')\n",
    "    plt.plot(predict(torch.tensor([0.,0.]), exact_parameters),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fc675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2000cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
