{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation of EEGLearn - P. Bashivan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a short summary of Pytorch implementation of the models described in \"Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks.\" Bashivan et al. at International conference on learning representations (2016).\n",
    "\n",
    "The rest of the code is in the different python scripts of this repo.\n",
    "\n",
    "All the codes have been inspired from the [original github](https://github.com/pbashivan/EEGLearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import os \n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from Utils import *\n",
    "from Models import *\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the original Images \n",
    "The images have directly been taken from original implementation, given that they remain the same nevermind the implementation (Pytorch, Tensorflow, Theano)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2670, 3, 32, 32)\n",
      "(7, 2670, 3, 32, 32)\n",
      "(2670,)\n",
      "(2670,)\n"
     ]
    }
   ],
   "source": [
    "Mean_Images = sio.loadmat(\"Sample Data/images.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Mean_Images)) \n",
    "Images = sio.loadmat(\"Sample Data/images_time.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Images)) \n",
    "Label = (sio.loadmat(\"Sample Data/FeatureMat_timeWin\")[\"features\"][:,-1]-1).astype(int) #corresponding to the signal label (i.e. load levels).\n",
    "print(np.shape(Label)) \n",
    "Patient_id = sio.loadmat(\"Sample Data/trials_subNums.mat\")['subjectNum'][0] #corresponding to the patient id\n",
    "print(np.shape(Patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2670, 7, 3, 32, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Images,(1,0,2,3,4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_t = np.transpose(Images,(1,0,2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading patient dataset \n",
    "From the total data, we select the images corresponding patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose among the patient : [ 1  2  3  4  6  7  8  9 10 11 12 14 15]\n"
     ]
    }
   ],
   "source": [
    "print(\"Choose among the patient : \"+str(np.unique(Patient_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_patient = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: BasicCNN\n",
    "First Implementation of a CNN on the Mean Images from each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label[Patient_id==choosen_patient], image=Mean_Images[Patient_id==choosen_patient])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = TrainTest_Model(BasicCNN, Trainloader, Testloader, n_epoch=50, learning_rate=0.001, print_epoch=-1, opti='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpool CNN\n",
    "Build the Max-pooling model performing a maxpool over the 7 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label[Patient_id==choosen_patient], image=Images_t[Patient_id==choosen_patient])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 8\n",
      "[5,  45]\tloss: 0.790\tAccuracy : 0.671\t\tval-loss: 1.850\tval-Accuracy : 0.526\n",
      "[10,  45]\tloss: 0.197\tAccuracy : 0.935\t\tval-loss: 0.661\tval-Accuracy : 0.895\n",
      "[15,  45]\tloss: 0.411\tAccuracy : 0.839\t\tval-loss: 1.761\tval-Accuracy : 0.737\n",
      "[20,  45]\tloss: 0.070\tAccuracy : 0.981\t\tval-loss: 0.697\tval-Accuracy : 0.868\n",
      "[25,  45]\tloss: 0.003\tAccuracy : 1.000\t\tval-loss: 1.094\tval-Accuracy : 0.842\n",
      "[30,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.327\tval-Accuracy : 0.895\n",
      "[35,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.457\tval-Accuracy : 0.921\n",
      "[40,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.536\tval-Accuracy : 0.921\n",
      "[45,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 1.598\tval-Accuracy : 0.921\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(MaxCNN, Trainloader, Testloader, n_epoch=45, learning_rate=0.001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp CNN\n",
    "FBuild the Conv1D model performing a convolution1D over the 7 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 8\n",
      "[5,  45]\tloss: 0.723\tAccuracy : 0.729\t\tval-loss: 0.770\tval-Accuracy : 0.658\n",
      "[10,  45]\tloss: 0.063\tAccuracy : 0.968\t\tval-loss: 0.314\tval-Accuracy : 0.789\n",
      "[15,  45]\tloss: 0.046\tAccuracy : 0.981\t\tval-loss: 0.266\tval-Accuracy : 0.895\n",
      "[20,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.403\tval-Accuracy : 0.895\n",
      "[25,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.458\tval-Accuracy : 0.895\n",
      "[30,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.477\tval-Accuracy : 0.868\n",
      "[35,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.488\tval-Accuracy : 0.868\n",
      "[40,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.501\tval-Accuracy : 0.868\n",
      "[45,  45]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.514\tval-Accuracy : 0.868\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(TempCNN, Trainloader, Testloader, n_epoch=45, learning_rate=0.001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM CNN\n",
    "Build the LSTM model applying a RNN over the 7 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label[Patient_id==choosen_patient], image=Images_t[Patient_id==choosen_patient])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 8\n",
      "[5,  45]\tloss: 1.367\tAccuracy : 0.323\t\tval-loss: 1.445\tval-Accuracy : 0.158\n",
      "[10,  45]\tloss: 1.130\tAccuracy : 0.490\t\tval-loss: 1.197\tval-Accuracy : 0.395\n",
      "[15,  45]\tloss: 0.721\tAccuracy : 0.761\t\tval-loss: 0.777\tval-Accuracy : 0.737\n",
      "[20,  45]\tloss: 0.325\tAccuracy : 0.916\t\tval-loss: 0.548\tval-Accuracy : 0.842\n",
      "[25,  45]\tloss: 0.157\tAccuracy : 0.961\t\tval-loss: 0.284\tval-Accuracy : 0.868\n",
      "[30,  45]\tloss: 0.082\tAccuracy : 0.987\t\tval-loss: 0.152\tval-Accuracy : 0.921\n",
      "[35,  45]\tloss: 0.031\tAccuracy : 0.994\t\tval-loss: 0.084\tval-Accuracy : 0.974\n",
      "[40,  45]\tloss: 0.015\tAccuracy : 1.000\t\tval-loss: 0.080\tval-Accuracy : 0.974\n",
      "[45,  45]\tloss: 0.010\tAccuracy : 1.000\t\tval-loss: 0.102\tval-Accuracy : 0.974\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(LSTM, Trainloader, Testloader, n_epoch=45, learning_rate=0.0001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix CNN\n",
    "Build the LSTM model applying a RNN and a CNN over the 7 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label[Patient_id==choosen_patient], image=Images_t[Patient_id==choosen_patient])\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training for Patient 8\n",
      "[5, 100]\tloss: 1.372\tAccuracy : 0.323\t\tval-loss: 1.417\tval-Accuracy : 0.158\n",
      "[10, 100]\tloss: 1.368\tAccuracy : 0.323\t\tval-loss: 1.434\tval-Accuracy : 0.158\n",
      "[15, 100]\tloss: 1.364\tAccuracy : 0.323\t\tval-loss: 1.441\tval-Accuracy : 0.158\n",
      "[20, 100]\tloss: 1.348\tAccuracy : 0.323\t\tval-loss: 1.439\tval-Accuracy : 0.158\n",
      "[25, 100]\tloss: 1.284\tAccuracy : 0.323\t\tval-loss: 1.426\tval-Accuracy : 0.158\n",
      "[30, 100]\tloss: 1.160\tAccuracy : 0.355\t\tval-loss: 1.371\tval-Accuracy : 0.237\n",
      "[35, 100]\tloss: 1.024\tAccuracy : 0.619\t\tval-loss: 1.284\tval-Accuracy : 0.474\n",
      "[40, 100]\tloss: 0.897\tAccuracy : 0.697\t\tval-loss: 1.221\tval-Accuracy : 0.553\n",
      "[45, 100]\tloss: 0.771\tAccuracy : 0.781\t\tval-loss: 1.149\tval-Accuracy : 0.605\n",
      "[50, 100]\tloss: 0.637\tAccuracy : 0.832\t\tval-loss: 1.047\tval-Accuracy : 0.737\n",
      "[55, 100]\tloss: 0.492\tAccuracy : 0.871\t\tval-loss: 0.908\tval-Accuracy : 0.789\n",
      "[60, 100]\tloss: 0.360\tAccuracy : 0.890\t\tval-loss: 0.714\tval-Accuracy : 0.789\n",
      "[65, 100]\tloss: 0.266\tAccuracy : 0.897\t\tval-loss: 0.539\tval-Accuracy : 0.816\n",
      "[70, 100]\tloss: 0.191\tAccuracy : 0.955\t\tval-loss: 0.429\tval-Accuracy : 0.842\n",
      "[75, 100]\tloss: 0.134\tAccuracy : 0.961\t\tval-loss: 0.367\tval-Accuracy : 0.842\n",
      "[80, 100]\tloss: 0.094\tAccuracy : 0.981\t\tval-loss: 0.329\tval-Accuracy : 0.842\n",
      "[85, 100]\tloss: 0.068\tAccuracy : 0.981\t\tval-loss: 0.309\tval-Accuracy : 0.842\n",
      "[90, 100]\tloss: 0.050\tAccuracy : 0.987\t\tval-loss: 0.297\tval-Accuracy : 0.842\n",
      "[95, 100]\tloss: 0.037\tAccuracy : 0.994\t\tval-loss: 0.289\tval-Accuracy : 0.868\n",
      "[100, 100]\tloss: 0.028\tAccuracy : 0.994\t\tval-loss: 0.282\tval-Accuracy : 0.868\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training for Patient '+str(choosen_patient))\n",
    "res = TrainTest_Model(Mix, Trainloader, Testloader, n_epoch=100, learning_rate=0.00001, print_epoch=5, opti='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
