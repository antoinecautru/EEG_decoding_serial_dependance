{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation of EEGLearn - P. Bashivan\n",
    "## Application: orientation decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a short summary of Pytorch implementation of the models described in \"Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks.\" Bashivan et al. at International conference on learning representations (2016).\n",
    "\n",
    "The rest of the code is in the different python scripts of this repo.\n",
    "\n",
    "All the codes have been inspired from the [original github](https://github.com/pbashivan/EEGLearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates from LPSY lab (2023):\n",
    "The networks had to be modified to match the new library version of pytorch. Also, many functions were adapted to our classification task.\n",
    "In addition to that, we noticed that using a Selu instead of a Relu activation function would improve the results. This might result from the vanishing gradient problem encountered by the Relu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\antoine\\documents\\epfl_ma4\\lab\\dnn_sd\\sd_dnn_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import os \n",
    "from os import path\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from Utils import *\n",
    "from Models import *\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['09','10','11','12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in participants:\n",
    "    if not path.exists(f\"Data_LPSY/{participant}_images_time.mat\"):\n",
    "        print(f\"Time Windom Images didn't exist need to be created for participant {participant}\")\n",
    "        create_img(PATH=\"Data_LPSY\", Nelectrodes=128, participant=participant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the original Images \n",
    "The images have directly been taken from original implementation, given that they remain the same nevermind the implementation (Pytorch, Tensorflow, Theano)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3419, 5, 3, 32, 32)\n",
      "(3419,)\n"
     ]
    }
   ],
   "source": [
    "# Mean_Images = sio.loadmat(\"Data_LPSY/images.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "#print(np.shape(Mean_Images)) \n",
    "Images_t = np.vstack([np.transpose(sio.loadmat(f\"Data_LPSY/{participant}_images_time.mat\")[\"img\"],(1,0,2,3,4)) for participant in participants])\n",
    "#corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Images_t)) \n",
    "Orientation = np.concatenate([(sio.loadmat(f\"Data_LPSY/{participant}_Orientations.mat\")[\"orientation\"]).reshape(-1) for participant in participants])\n",
    "#corresponding to the signal label (i.e. load levels).\n",
    "Label = (Orientation/20).astype(int)\n",
    "print(np.shape(Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the \"stripes\" type only (in which orientation seems easier to decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimType = np.concatenate([(sio.loadmat(f\"Data_LPSY/{participant}_Labels.mat\")[\"label\"]).reshape(-1) for participant in participants])\n",
    "Stripes_mask = stimType == 0\n",
    "Images_t = Images_t[Stripes_mask]\n",
    "Label = Label[Stripes_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpool CNN\n",
    "Build the Max-pooling model performing a maxpool over the 5 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images_t)\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  45]\tloss: 2.193\tAccuracy : 0.124\t\tval-loss: 2.207\tval-Accuracy : 0.079\n",
      "[10,  45]\tloss: 2.186\tAccuracy : 0.138\t\tval-loss: 2.209\tval-Accuracy : 0.085\n",
      "[15,  45]\tloss: 2.175\tAccuracy : 0.165\t\tval-loss: 2.212\tval-Accuracy : 0.082\n",
      "[20,  45]\tloss: 2.153\tAccuracy : 0.179\t\tval-loss: 2.223\tval-Accuracy : 0.103\n",
      "[25,  45]\tloss: 2.120\tAccuracy : 0.204\t\tval-loss: 2.241\tval-Accuracy : 0.106\n",
      "[30,  45]\tloss: 2.075\tAccuracy : 0.230\t\tval-loss: 2.263\tval-Accuracy : 0.100\n",
      "[35,  45]\tloss: 2.015\tAccuracy : 0.261\t\tval-loss: 2.290\tval-Accuracy : 0.091\n",
      "[40,  45]\tloss: 1.936\tAccuracy : 0.303\t\tval-loss: 2.316\tval-Accuracy : 0.088\n",
      "[45,  45]\tloss: 1.835\tAccuracy : 0.360\t\tval-loss: 2.344\tval-Accuracy : 0.094\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(MaxCNN, Trainloader, Testloader, n_epoch=45, learning_rate=0.00001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=9, n_window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp CNN\n",
    "FBuild the Conv1D model performing a convolution1D over the 5 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  45]\tloss: 2.195\tAccuracy : 0.118\t\tval-loss: 2.202\tval-Accuracy : 0.082\n",
      "[10,  45]\tloss: 2.191\tAccuracy : 0.128\t\tval-loss: 2.203\tval-Accuracy : 0.082\n",
      "[15,  45]\tloss: 2.179\tAccuracy : 0.217\t\tval-loss: 2.205\tval-Accuracy : 0.103\n",
      "[20,  45]\tloss: 2.112\tAccuracy : 0.244\t\tval-loss: 2.222\tval-Accuracy : 0.106\n",
      "[25,  45]\tloss: 1.945\tAccuracy : 0.311\t\tval-loss: 2.299\tval-Accuracy : 0.132\n",
      "[30,  45]\tloss: 1.759\tAccuracy : 0.400\t\tval-loss: 2.407\tval-Accuracy : 0.126\n",
      "[35,  45]\tloss: 1.577\tAccuracy : 0.464\t\tval-loss: 2.530\tval-Accuracy : 0.138\n",
      "[40,  45]\tloss: 1.386\tAccuracy : 0.540\t\tval-loss: 2.678\tval-Accuracy : 0.129\n",
      "[45,  45]\tloss: 1.177\tAccuracy : 0.632\t\tval-loss: 2.877\tval-Accuracy : 0.126\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(TempCNN, Trainloader, Testloader, n_epoch=45, learning_rate=0.00001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=9, n_window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM CNN\n",
    "Build the LSTM model applying a RNN over the 5 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images_t)\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  45]\tloss: 2.192\tAccuracy : 0.150\t\tval-loss: 2.199\tval-Accuracy : 0.132\n",
      "[10,  45]\tloss: 2.183\tAccuracy : 0.194\t\tval-loss: 2.199\tval-Accuracy : 0.117\n",
      "[15,  45]\tloss: 2.167\tAccuracy : 0.217\t\tval-loss: 2.199\tval-Accuracy : 0.114\n",
      "[20,  45]\tloss: 2.144\tAccuracy : 0.227\t\tval-loss: 2.201\tval-Accuracy : 0.123\n",
      "[25,  45]\tloss: 2.114\tAccuracy : 0.262\t\tval-loss: 2.203\tval-Accuracy : 0.126\n",
      "[30,  45]\tloss: 2.075\tAccuracy : 0.291\t\tval-loss: 2.209\tval-Accuracy : 0.144\n",
      "[35,  45]\tloss: 2.026\tAccuracy : 0.318\t\tval-loss: 2.221\tval-Accuracy : 0.138\n",
      "[40,  45]\tloss: 1.965\tAccuracy : 0.355\t\tval-loss: 2.241\tval-Accuracy : 0.129\n",
      "[45,  45]\tloss: 1.888\tAccuracy : 0.398\t\tval-loss: 2.270\tval-Accuracy : 0.117\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(LSTM, Trainloader, Testloader, n_epoch=45, learning_rate=0.00001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=9, n_window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix CNN\n",
    "Build the LSTM model applying a RNN and a CNN over the 5 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images_t)\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  60]\tloss: 2.193\tAccuracy : 0.120\t\tval-loss: 2.202\tval-Accuracy : 0.091\n",
      "[10,  60]\tloss: 2.178\tAccuracy : 0.200\t\tval-loss: 2.204\tval-Accuracy : 0.100\n",
      "[15,  60]\tloss: 2.114\tAccuracy : 0.245\t\tval-loss: 2.218\tval-Accuracy : 0.106\n",
      "[20,  60]\tloss: 1.973\tAccuracy : 0.295\t\tval-loss: 2.277\tval-Accuracy : 0.109\n",
      "[25,  60]\tloss: 1.801\tAccuracy : 0.387\t\tval-loss: 2.367\tval-Accuracy : 0.117\n",
      "[30,  60]\tloss: 1.601\tAccuracy : 0.469\t\tval-loss: 2.485\tval-Accuracy : 0.111\n",
      "[35,  60]\tloss: 1.354\tAccuracy : 0.576\t\tval-loss: 2.652\tval-Accuracy : 0.138\n",
      "[40,  60]\tloss: 1.033\tAccuracy : 0.702\t\tval-loss: 2.903\tval-Accuracy : 0.132\n",
      "[45,  60]\tloss: 0.674\tAccuracy : 0.862\t\tval-loss: 3.313\tval-Accuracy : 0.123\n",
      "[50,  60]\tloss: 0.383\tAccuracy : 0.955\t\tval-loss: 3.847\tval-Accuracy : 0.132\n",
      "[55,  60]\tloss: 0.203\tAccuracy : 0.990\t\tval-loss: 4.387\tval-Accuracy : 0.117\n",
      "[60,  60]\tloss: 0.110\tAccuracy : 0.999\t\tval-loss: 4.901\tval-Accuracy : 0.106\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(Mix, Trainloader, Testloader, n_epoch=60, learning_rate=0.00001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=9, n_window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
