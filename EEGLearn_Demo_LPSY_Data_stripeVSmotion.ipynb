{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation of EEGLearn - P. Bashivan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a short summary of Pytorch implementation of the models described in \"Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks.\" Bashivan et al. at International conference on learning representations (2016).\n",
    "\n",
    "The rest of the code is in the different python scripts of this repo.\n",
    "\n",
    "All the codes have been inspired from the [original github](https://github.com/pbashivan/EEGLearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\antoine\\documents\\epfl_ma4\\lab\\dnn_sd\\sd_dnn_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import os \n",
    "from os import path\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "\n",
    "from Utils import *\n",
    "from Models import *\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in participants:\n",
    "    if not path.exists(f\"Data_LPSY/{participant}_images_time.mat\"):\n",
    "        print(f\"Time Windom Images didn't exist need to be created for participant {participant}\")\n",
    "        create_img(PATH=\"Data_LPSY\", Nelectrodes=128, participant=participant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the original Images \n",
    "The images have directly been taken from original implementation, given that they remain the same nevermind the implementation (Pytorch, Tensorflow, Theano)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 862, 3, 32, 32)\n",
      "(862,)\n"
     ]
    }
   ],
   "source": [
    "# Mean_Images = sio.loadmat(\"Data_LPSY/images.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "#print(np.shape(Mean_Images)) \n",
    "Images = sio.loadmat(f\"Data_LPSY/{participant}_images_time.mat\")[\"img\"] #corresponding to the images mean for all the seven windows\n",
    "print(np.shape(Images)) \n",
    "Label = (sio.loadmat(f\"Data_LPSY/{participant}_Labels.mat\")[\"label\"]).reshape(-1) #corresponding to the signal label (i.e. load levels).\n",
    "print(np.shape(Label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 5, 3, 32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Images,(1,0,2,3,4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_t = np.transpose(Images,(1,0,2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpool CNN\n",
    "Build the Max-pooling model performing a maxpool over the 5 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images_t)\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  25]\tloss: 0.161\tAccuracy : 0.926\t\tval-loss: 0.292\tval-Accuracy : 0.913\n",
      "[10,  25]\tloss: 0.144\tAccuracy : 0.941\t\tval-loss: 0.156\tval-Accuracy : 0.959\n",
      "[15,  25]\tloss: 0.030\tAccuracy : 0.986\t\tval-loss: 0.274\tval-Accuracy : 0.924\n",
      "[20,  25]\tloss: 0.001\tAccuracy : 1.000\t\tval-loss: 0.253\tval-Accuracy : 0.942\n",
      "[25,  25]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.271\tval-Accuracy : 0.942\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(MaxCNN, Trainloader, Testloader, n_epoch=25, learning_rate=0.001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=2, n_window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp CNN\n",
    "FBuild the Conv1D model performing a convolution1D over the 5 parallel convnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  30]\tloss: 0.161\tAccuracy : 0.942\t\tval-loss: 0.229\tval-Accuracy : 0.924\n",
      "[10,  30]\tloss: 0.007\tAccuracy : 0.997\t\tval-loss: 0.384\tval-Accuracy : 0.924\n",
      "[15,  30]\tloss: 0.011\tAccuracy : 0.996\t\tval-loss: 0.238\tval-Accuracy : 0.936\n",
      "[20,  30]\tloss: 0.097\tAccuracy : 0.971\t\tval-loss: 0.388\tval-Accuracy : 0.924\n",
      "[25,  30]\tloss: 0.116\tAccuracy : 0.970\t\tval-loss: 0.347\tval-Accuracy : 0.953\n",
      "[30,  30]\tloss: 0.018\tAccuracy : 0.996\t\tval-loss: 0.228\tval-Accuracy : 0.953\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(TempCNN, Trainloader, Testloader, n_epoch=30, learning_rate=0.001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=2, n_window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM CNN\n",
    "Build the LSTM model applying a RNN over the 5 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images_t)\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  30]\tloss: 0.133\tAccuracy : 0.949\t\tval-loss: 0.319\tval-Accuracy : 0.872\n",
      "[10,  30]\tloss: 0.015\tAccuracy : 0.999\t\tval-loss: 0.290\tval-Accuracy : 0.919\n",
      "[15,  30]\tloss: 0.011\tAccuracy : 0.999\t\tval-loss: 0.448\tval-Accuracy : 0.895\n",
      "[20,  30]\tloss: 0.023\tAccuracy : 0.991\t\tval-loss: 0.439\tval-Accuracy : 0.913\n",
      "[25,  30]\tloss: 0.002\tAccuracy : 1.000\t\tval-loss: 0.239\tval-Accuracy : 0.936\n",
      "[30,  30]\tloss: 0.000\tAccuracy : 1.000\t\tval-loss: 0.287\tval-Accuracy : 0.936\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(LSTM, Trainloader, Testloader, n_epoch=30, learning_rate=0.0001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=2, n_window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix CNN\n",
    "Build the LSTM model applying a RNN and a CNN over the 5 parallel convnets outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = EEGImagesDataset(label=Label, image=Images_t)\n",
    "\n",
    "lengths = [int(len(EEG)*train_part+1), int(len(EEG)*test_part)]\n",
    "Train, Test = random_split(EEG, lengths)\n",
    "\n",
    "Trainloader = DataLoader(Train,batch_size=batch_size)\n",
    "Testloader = DataLoader(Test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training\n",
      "[5,  45]\tloss: 0.498\tAccuracy : 0.828\t\tval-loss: 0.465\tval-Accuracy : 0.791\n",
      "[10,  45]\tloss: 0.208\tAccuracy : 0.930\t\tval-loss: 0.246\tval-Accuracy : 0.890\n",
      "[15,  45]\tloss: 0.130\tAccuracy : 0.949\t\tval-loss: 0.207\tval-Accuracy : 0.901\n",
      "[20,  45]\tloss: 0.086\tAccuracy : 0.978\t\tval-loss: 0.206\tval-Accuracy : 0.901\n",
      "[25,  45]\tloss: 0.054\tAccuracy : 0.991\t\tval-loss: 0.222\tval-Accuracy : 0.919\n",
      "[30,  45]\tloss: 0.030\tAccuracy : 0.994\t\tval-loss: 0.250\tval-Accuracy : 0.919\n",
      "[35,  45]\tloss: 0.015\tAccuracy : 1.000\t\tval-loss: 0.282\tval-Accuracy : 0.930\n",
      "[40,  45]\tloss: 0.008\tAccuracy : 1.000\t\tval-loss: 0.311\tval-Accuracy : 0.930\n",
      "[45,  45]\tloss: 0.005\tAccuracy : 1.000\t\tval-loss: 0.336\tval-Accuracy : 0.930\n"
     ]
    }
   ],
   "source": [
    "print('Begin Training')\n",
    "res = TrainTest_Model(Mix, Trainloader, Testloader, n_epoch=45, learning_rate=0.00001, print_epoch=5, opti='Adam',\n",
    "                     n_classes=2, n_window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
